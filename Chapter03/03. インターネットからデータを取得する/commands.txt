julia> ]
(v1.0) pkg> add HTTP 
(v1.0) pkg> add Gumbo 
(v1.0) pkg> add Cascadia 


using HTTP, Gumbo, Cascadia

r=HTTP.get("https://github.com/JuliaWeb");

page_body = String(r.body);

h = Gumbo.parsehtml(page_body);

qs = HTMLElement[]
Cascadia.matchAllInto(sel"h3 .d-inline-block", h.root, qs);
names_links = Tuple{String, String}[]
for q in qs
    name = strip(nodeText(q))
    link = q.attributes["href"]
    push!(names_links, (name, link))
end

julia> names_links

julia> stats = Dict{String,String}()
julia> @sync for (name, link) in names_links
    @async begin
        r2 = HTTP.get("https://github.com"*link);
        h2 = parsehtml(String(r2.body));
        qs2 = HTMLElement[]
        Cascadia.matchAllInto(sel".social-count.js-social-count", h2.root, qs2);
        stats[name] = strip(nodeText(qs2[1]))
    end
end


julia> stats

julia> stats2 = Dict(key => parse(Int64, stats[key]) for key in keys(stats))

julia> m = maximum(values(stats2))


julia> ]
(v1.2) pkg> add PyCall 
(v1.2) pkg> add Conda 

using PyCall
using Conda
Conda.add("scrapy")

ssel = pyimport("scrapy.selector")

julia> s = ssel.Selector(text=page_body)

julia> elems = s.xpath("//a[@itemprop='name codeRepository']")

julia> strip(elems[1].xpath("text()")[1].extract())

julia> strip(elems[2].xpath("text()")[1].extract())

julia> a = elems[1].xpath("@href")[1].extract()

julia> a = elems[2].xpath("@href")[1].extract()
